syntax = "proto3";

package meadowrun;


message StringPair {
    string key = 1;
    string value = 2;
}


// Represents a folder (or folders) that contain code that the meadowrun server can
// access directly
message ServerAvailableFolder {
    // code_paths[0] will be set as the working directory, and all code_paths will be
    // added to the PYTHONPATH. These code_paths must "make sense" on the machine where
    // the meadowrun agent is running. One typical use case for this is that the
    // meadowrun agents have access to a shared filesystem where code has been deployed.
    // Order matters as usual for PYTHONPATH. Another typical use case is to provide no
    // code_paths because all of the code needed is already specified in the
    // interpreter_deployment
    repeated string code_paths = 1;
}

message CodeZipFile {
    // A single zip file that contains code which will be unzipped and made available.
    // All code_paths are relative to the zip file's root, and will be added to the
    // PYTHONPATH. Order matters as usual for PYTHONPATH.
    // Current working directory path is also relative to zip root, and should be the folder
    // where the command/function is exectued on the remote side.
    // The zip file is located by URL.
    // For s3 this is s3://bucket-name/key-name
    // For files this is file://path/to/file
    string url = 1;
    repeated string code_paths = 2;
    string cwd_path = 3;
}


// Represents a git repo at a specific commit
message GitRepoCommit {
    // specifies the url, will be provided to git clone, see
    // https://git-scm.com/docs/git-clone
    string repo_url = 1;

    // specifies the commit to use, will be provided to git checkout [commit] see
    // https://git-scm.com/book/en/v2/Git-Tools-Revision-Selection
    string commit = 2;

    // specifies a relative path within the repo to treat as the "root" directory for
    // the purposes of this deployment
    string path_to_source = 3;
}


// Represents a git repo on a specific branch. Note that this is NOT deterministic as
// the coordinator will resolve the branch to a specific commit. In order to reproduce
// any results, the code must be run with the specific commit that this resolves to, NOT
// the branch that was originally specified. This should only be used when GitRepoBranch
// cannot be resolved to a GitRepoCommit on the client.
message GitRepoBranch {
    // specifies the url, will be provided to git clone, see
    // https://git-scm.com/docs/git-clone
    string repo_url = 1;

    // specifies the branch to use
    string branch = 2;

    // specifies a relative path within the repo to treat as the "root" directory for
    // the purposes of this deployment
    string path_to_source = 3;
}


// Represents an interpreter that the meadowrun server can access directly.
// interpreter_path can be set to meadowrun.config.MEADOWRUN_INTERPRETER to indicate
// that this job should run using the same interpreter that's being used to run
// meadowrun, which is only recommended for testing.
message ServerAvailableInterpreter {
    string interpreter_path = 1;
}


// Represents a specific version (aka digest) of a container
message ContainerAtDigest {
    // Together, repository and digest should be such that `docker pull
    // [repository]@[digest]` works
    string repository = 1;
    string digest = 2;
}


// Represents a tag of a container. Note that this is NOT deterministic as the
// coordinator will resolve the tag to a specific digest. In order to reproduce any
// results, the code must be run with the specific digest that this resolves to, NOT the
// tag that was originally specified. This should only be used when ContainerAtTag
// cannot be resolved to a ContainerAtDigest on the client.
message ContainerAtTag {
    // Together, repository and tag should be such that `docker pull [repository]:[tag]`
    // works. The container should be configured so that `docker run [repository]:[tag]
    // python [additional arguments]` behaves as expected
    string repository = 1;
    string tag = 2;
}

enum EnvironmentType {
    // Reserved, not used
    DEFAULT = 0;
    CONDA = 1;
    PIP = 2;
    POETRY = 3;
}

// Represents the path to an environment spec in the code deployment.
// An environment spec is a list of packages to install, in a format that
// the package manager can understand.
// It is not necessarily reproducible, e.g.
// if it doesn't contain all transitive dependencies or full version numbers.
// It is also not necessarily cross-platform.
message EnvironmentSpecInCode {
    EnvironmentType environment_type = 1;
    string path_to_spec = 2;
    // python version is not used for CONDA environments
    string python_version = 3;
    // right now just cuda is supported, maps software -> version requirement
    map<string, string> additional_software = 5;
    // whether to support editable install of the code in the environment, e.g. register
    // cmd line scripts, or build metadata.
    bool editable_install = 6;
}

// Represents an environment spec represented as a string.
// An environment spec is a list of packages to install, in a format that
// the package manager can understand.
// e.g. output of "conda env export"
message EnvironmentSpec {
    EnvironmentType environment_type = 1;
    string spec = 2;
    // only applicable for poetry
    string spec_lock = 3;
    // python version is not used for CONDA environments
    string python_version = 4;
    // right now just cuda is supported, maps software -> version requirement
    map<string, string> additional_software = 5;
    // whether to support editable install of the code in the environment, e.g. register
    // cmd line scripts, or build metadata.
    // TODO this is not supported yet for EnvironmentSpec, but not adding it here
    // leads to a bunch more of annoying if/thens.
    bool editable_install = 6;
}


// Only recommended for testing. Represents a container image that already exists on the
// meadowrun server. Helpful for testing with locally built images that haven't been
// uploaded to a repository and don't have a digest
message ServerAvailableContainer {
    string image_name = 1;
}


message PyCommandJob {
    repeated string command_line = 1;
    bytes pickled_context_variables = 2;
}


message QualifiedFunctionName {
    string module_name = 1;
    string function_name = 2;
}


message PyFunctionJob {
    oneof function_spec {
        QualifiedFunctionName qualified_function_name = 1;
        bytes pickled_function = 2;
    }
    bytes pickled_function_arguments = 3;
}

message PyAgentJob {
    oneof function_spec {
        QualifiedFunctionName qualified_function_name = 1;
        bytes pickled_function = 2;
    }
    QualifiedFunctionName qualified_agent_function_name = 5;
    bytes pickled_agent_function_arguments = 4;
}


message GridTask {
    int32 task_id = 1;
    int32 attempt = 3;
    bytes pickled_function_arguments = 2;
}


message ContainerImage {
    oneof container_image {
        ContainerAtDigest container_image_at_digest = 1;
        ContainerAtTag container_image_at_tag = 2;
        ServerAvailableContainer server_available_container_image = 3;
    }
}


message Job {

    // job_id uniquely identifies this request to avoid duplicates and for getting the
    // results later. Make sure job_id is unique! Multiple requests with the same job_id
    // will be treated as duplicates even if all of the other parameters are different.
    // Also, job_id may only use string.ascii_letters, numbers, ., -, and _.
    string job_id = 1;
    string job_friendly_name = 2;

    oneof code_deployment {
        ServerAvailableFolder server_available_folder = 5;
        GitRepoCommit git_repo_commit = 6;
        GitRepoBranch git_repo_branch = 7;
        CodeZipFile code_zip_file = 19;
    }
    oneof interpreter_deployment {
        ServerAvailableInterpreter server_available_interpreter = 8;

        // The container specified should be such that running `docker run
        // [repository]@[digest] python --version` works. Currently only works with
        // Linux containers. If code_deployment specifies any code folders, they will be
        // mounted in the container as /meadowrun/code0, /meadowrun/code1, etc.
        ContainerAtDigest container_at_digest = 9;
        ContainerAtTag container_at_tag = 10;

        ServerAvailableContainer server_available_container = 11;

        EnvironmentSpecInCode environment_spec_in_code = 12;
        EnvironmentSpec environment_spec = 18;
    }

    repeated ContainerImage sidecar_containers = 22;

    repeated StringPair environment_variables = 13;

    // result_highest_pickle_protocol tells the remote code what the highest pickle
    // protocol we can read on this end is which will help it determine what pickle
    // protocol to use to send back results. This should almost always be set to
    // pickle.HIGHEST_PROTOCOL in the calling python process
    int32 result_highest_pickle_protocol = 14;

    // determines what kind of job this is
    oneof job_spec {
        PyCommandJob py_command = 15;
        PyFunctionJob py_function = 16;
        PyAgentJob py_agent = 23;
    }

    repeated CredentialsSourceMessage credentials_sources = 17;

    repeated string ports = 20;
    bool uses_gpu = 21;
}


// Represents the state of a process, can apply to a job or a grid task
message ProcessState {
    enum ProcessStateEnum {
        // Reserved, not used
        DEFAULT = 0;

        // These states represent a job that is "in progress"

        // The meadowrun coordinator has received the Job
        RUN_REQUESTED = 1;

        // The assigned agent has launched the job. pid and log_file_name will be
        // populated.
        RUNNING = 2;

        // These states represent a job that is "done". log_file_name, return_code, and
        // one of pid/container_id will be populated unless otherwise noted.

        // The job has completed normally. pickled_result may be populated.
        SUCCEEDED = 3;
        // There was an exception before launching the job process. pid/container_id,
        // log_file_name, and return_code will not be populated. pickled_result will be
        // populated with a tuple representing the python exception from the agent
        // process (see PYTHON_EXCEPTION for the format).
        RUN_REQUEST_FAILED = 4;
        // A python exception was thrown from the job process. pickled_result will be a
        // pickled tuple (exception_type, exception_message, exception_traceback). We
        // don't pickle the exception itself because it may not be unpicklable on this
        // end (e.g. it involves types that don't exist in the current process' code
        // base). Exceptions are by their nature unexpected, so we shouldn't expect that
        // they can be unpickled on the client.
        PYTHON_EXCEPTION = 5;
        // The process exited with a non-zero return code. This could mean that a
        // non-python exception was thrown (e.g. in the interpreter itself, or in a C
        // extension), or os.exit was called with a non-zero argument, or there was a
        // python exception thrown in the meadowrun worker code.
        NON_ZERO_RETURN_CODE = 6;
        // We do not have any agents that are capable of running the job given its
        // resource requirements. Either reduce the resource requirements of the job or
        // launch agents that have enough resources.
        RESOURCES_NOT_AVAILABLE = 7;

        // There was an error while reading the outputs of the process. This could mean
        // that the child process somehow silently failed to write its outputs correctly
        // or there was a python exception thrown in the meadowrun worker code.
        ERROR_GETTING_STATE = 8;

        // (run_map only) The task worker process exited unexpectedly. This can mean the
        // task called exit(), or it crashed.
        UNEXPECTED_WORKER_EXIT = 10;

        // This state represents a job that is neither "done" nor "in progress"

        // We do not know the job id
        UNKNOWN = 9;
    }
    ProcessStateEnum state = 1;
    int32 pid = 2;
    string container_id = 3;
    string log_file_name = 4;
    bytes pickled_result = 5;
    int32 return_code = 6;
    float max_memory_used_gb = 7;
}


// For updating the state of a job
message JobStateUpdate {
    string job_id = 1;
    ProcessState process_state = 2;
}


// For getting the state of a grid task
message GridTaskStateResponse {
    int32 task_id = 1;
    int32 attempt = 3;
    ProcessState process_state = 2;
}


// This represents a credentials source (see credentials.py)
message CredentialsSourceMessage {
    Credentials.Service service = 1;
    string service_url = 2;
    oneof source {
        AwsSecretProto aws_secret = 3;
        AzureSecretProto azure_secret = 5;
        ServerAvailableFile server_available_file = 4;
        KubernetesSecretProto kubernetes_secret = 6;
    }
}


// Represents actual credentials
message Credentials {
    enum Service {
        DEFAULT_SERVICE = 0;
        DOCKER = 1;
        GIT = 2;
    }

    enum Type {
        DEFAULT_TYPE = 0;
        USERNAME_PASSWORD = 1;
        SSH_KEY = 2;
    }

    bytes credentials = 1;
}


// Represents credentials stored in AWS. Must be accessible by the coordinator.
// - For credentials_type = USERNAME_PASSWORD: Expected keys are "username" and
//   "password", e.g. SecretString should be like
//   '{"username":"my_username","password":"my_password"}'
// - For credentials_type = SSH_KEY: Expected key is "private_key", which should contain
//   the contents of the SSH private key file
message AwsSecretProto {
    Credentials.Type credentials_type = 1;
    string secret_name = 2;
}


// Represents credentials stored in Azure
// - For credentials_type = USERNAME_PASSWORD, expects a json like '{"username":
//   "my_username", "password": "my_pasword}'
// - For credentials_type = SSH_KEY, expects a plain-text value containing the contents
//   of the SSH private key file
message AzureSecretProto {
    Credentials.Type credentials_type = 1;
    string vault_name = 2;
    string secret_name = 3;
}


// Represents credentials in a file. Must be a file accessible by the coordinator.
// - For credentials_type = USERNAME_PASSWORD: The file must have username on the first
//   line and password on the second line. Final newline character is optional
// - For credentials_type = SSH_KEY: The file should be an SSH private key file
message ServerAvailableFile {
    Credentials.Type credentials_type = 1;
    string path = 2;
}


// Represents credentials stored in Kubernetes. This class doesn't really need to be a
// protobuf because when we run on Kubernetes we don't actually need to serialize the
// Job object. But we made it a protobuf anyways because all of the other types of
// secrets are protobufs.
message KubernetesSecretProto {
    Credentials.Type credentials_type = 1;
    string secret_name = 2;
}
